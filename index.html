---
layout: default
---

<style>
    table {
        border: 0;
    }
    table td {
        border: 0;
    }
</style>

<table>
		<tbody>
			<tr>
				<td width="200">
                    <img height="200" src="images/me.jpg">
				</td>
				<td>
                    <!--<td style="vertical-align:bottom">-->
                    <font size="5">
                        <p><b>Jianfeng Wang</b></p>
                    </font>
                    <p>
                        Principal Researcher<br>
                        Microsoft, Redmond, WA<br>
                        <a href = "mailto: jianfw@microsoft.com">jianfw@microsoft.com</a>
                    </p>
				</td>
			</tr>
		</tbody>
</table>

<p align="justify">
I am a Principal Researcher at Microsoft Cloud and AI and focus on
large-scale multimodal representation learning recently.
I have broad research interest, including computer vision, e.g. image
classification, object detection, and vision-language intelligence, e.g.
vision-language pretraining, visual question answering.
Received the B.Eng. degree and PhD degree
from the University of Science and Technology of China (USTC).
</p>

<p>
<a href="https://github.com/amsword/">Github</a>,
<a href="https://scholar.google.com/citations?user=vJWEw_8AAAAJ&hl=en">Google Scholar</a>,
<a href="https://www.linkedin.com/in/jianfengwang1/">LinkedIn</a>,
<a href="post">Blogs</a>
</p>

<p> <font size="4"> <b>Projects</b> </font> </p>
<ul align="justify">
    <li> <p>
        ScaleApex: A simple way to combine fairscale and apex<br>
        <font size="2">
            <b>Jianfeng Wang</b> <br>
            7/2022 <a href="https://github.com/amsword/scaleapex">github</a>
        </font>
    </p> </li>

    <li> <p>
        AzFuse: A lightweight blobfuse-like python tool with the data transfer through azcopy<br>
        <font size="2">
            <b>Jianfeng Wang</b>
            <br>
            6/2022 <a href="https://github.com/microsoft/azfuse">github</a>
        </font>
    </p> </li>

    <li> <p>
        GIT: A Generative Image-to-text Transformer for Vision and Language <br>
        <font size="2">
            <b>Jianfeng Wang</b>, Zhengyuan Yang, Xiaowei Hu, Linjie Li, Kevin Lin, Zhe Gan, Zicheng Liu, Ce Liu, Lijuan Wang
            <br>
            5/2022 <a href="https://arxiv.org/pdf/2205.14100.pdf">arxiv-pdf</a>, <a href="https://github.com/microsoft/generativeimage2text">github</a>
        </font>
    </p> </li>

    <li> <p>
        Injecting Semantic Concepts into End-to-End Image Captioning
        <br>
        <font size="2">
            Zhiyuan Fang, <b>Jianfeng Wang</b>, Xiaowei Hu, Lin Liang, Zhe Gan, Lijuan Wang, Yezhou Yang, Zicheng Liu
            <br>
            12/2021 <a href="https://arxiv.org/abs/2112.05230">arxiv-pdf</a>
        </font>
    </p> </li>

    <li> <p>
        Scaling up vision-language pre-training for image captioning
        <br>
        <font size="2">
            Xiaowei Hu, Zhe Gan, <b>Jianfeng Wang</b>, Zhengyuan Yang, Zicheng Liu, Yumao Lu, Lijuan Wang
            <br>
            11/2021 <a href="https://arxiv.org/abs/2111.12233">arxiv-pdf</a>
        </font>
    </p> </li>

    <li><p>
        Crossing the Format Boundary of Text and Boxes: Towards Unified Vision-Language Modeling
        <br>
        <font size="2">
            Zhengyuan Yang, Zhe Gan, <b>Jianfeng Wang</b>, Xiaowei Hu, Faisal Ahmed, Zicheng Liu, Yumao Lu, Lijuan Wang
            <br>
            11/2021 <a href="https://arxiv.org/abs/2111.12085">arxiv-pdf</a>
        </font>
    </p></li>

    <li><p>
        UFO: A UniFied TransfOrmer for Vision-Language Representation Learning
        <br>
        <font size="2">
            <b>Jianfeng Wang</b>, Xiaowei Hu, Zhe Gan, Zhengyuan Yang, Xiyang Dai, Zicheng Liu, Yumao Lu, Lijuan Wang
            <br>
            11/2021 <a href="https://arxiv.org/abs/2111.10023">arxiv-pdf</a>
        </font>
    </p></li>

    <li><p>
        An Empirical Study of Training End-to-End Vision-and-Language Transformers
        <br>
        <font size="2">
            Zi-Yi Dou, Yichong Xu, Zhe Gan, <b>Jianfeng Wang</b>, Shuohang Wang, Lijuan Wang, Chenguang Zhu, Zicheng Liu, Michael Zeng
            <br>
            11/2021 <a href="https://arxiv.org/abs/2111.02387">arxiv-pdf</a>
        </font>
    </p></li>

    <li> <p>
        AML Command Transfer(ACT): A lightweight tool to transfer any command line to Azure Machine Learning services<br>
        <font size="2">
            <b>Jianfeng Wang</b>
            <br>
            12/2021 <a href="https://github.com/microsoft/act">github</a>
        </font>
    </p> </li>

    <li> <p>
        Florence: A New Foundation Model for Computer Vision <br>
        <font size="2">
            Lu Yuan, Dongdong Chen, Yi-Ling Chen, Noel Codella, Xiyang Dai, Jianfeng Gao, Houdong Hu, Xuedong Huang, Boxin Li, Chunyuan Li, Ce Liu, Mengchen Liu, Zicheng Liu, Yumao Lu, Yu Shi, Lijuan Wang, <b>Jianfeng Wang</b>, Bin Xiao, Zhen Xiao, Jianwei Yang, Michael Zeng, Luowei Zhou, Pengchuan Zhang<br>
            11/2021 <a href="https://arxiv.org/pdf/2111.11432.pdf">arxiv-pdf</a>
        </font>
    </p> </li>

    <li> <p>
        An Empirical Study of GPT-3 for Few-Shot Knowledge-Based VQA<br>
        <font size="2">
            Zhengyuan Yang, Zhe Gan, <b>Jianfeng Wang</b>, Xiaowei Hu, Yumao Lu, Zicheng Liu, Lijuan Wang
            <br>
            9/2021 <a href="https://arxiv.org/pdf/2109.05014.pdf">arxiv-pdf</a>
        </font>
    </p> </li>

    <li> <p>
        Is Object Detection Necessary for Human-Object Interaction Recognition?
        <font size="2">
            Ying Jin, Yinpeng Chen, Lijuan Wang, <b>Jianfeng Wang</b>, Pei Yu, Zicheng Liu, Jenq-Neng Hwang
            <br>
            7/2021 <a href="https://arxiv.org/abs/2107.13083">arxiv-pdf</a>
        </font>
    </p> </li>

    <li> <p>
        End-to-End Semi-Supervised Object Detection with Soft Teacher<br>
        <font size="2">
            Mengde Xu, Zheng Zhang, Han Hu, <b>Jianfeng Wang</b>, Lijuan Wang, Fangyun Wei, Xiang Bai, Zicheng Liu
            <br>
            4/2021 <a href="https://arxiv.org/pdf/2106.09018.pdf">arxiv-pdf</a>
        </font>
    </p> </li>

    <li> <p>
        Compressing Visual-Linguistic Model via Knowledge Distillation<br>
        <font size="2">
            Zhiyuan Fang, <b>Jianfeng Wang</b>, Xiaowei Hu, Lijuan Wang, Yezhou
            Yang, Zicheng Liu<br>
            4/2021 <a href="https://arxiv.org/pdf/2104.02096.pdf">arxiv-pdf</a>
        </font>
    </p> </li>

    <li> <p>
        DAP: Detection-Aware Pre-Training With Weak Supervision<br>
        <font size="2">
            Yuanyi Zhong, <b>Jianfeng Wang</b>, Lijuan Wang, Jian Peng, Yu-Xiong Wang, Lei Zhang
            <br>
            3/2021 <a href="https://arxiv.org/pdf/2103.16651.pdf">arxiv-pdf</a>
        </font>
    </p> </li>

    <li> <p>
        Seed: Self-Supervised Distillation for Visual Representation<br>
        <font size="2">
            Zhiyuan Fang, <b>Jianfeng Wang</b>, Lijuan Wang, Lei Zhang, Yezhou Yang, Zicheng Liu
            <br>
            1/2021 <a href="https://arxiv.org/pdf/2101.04731.pdf">arxiv-pdf</a>
        </font>
    </p> </li>

    <li> <p>
        TAP: Text-Aware Pre-training for Text-VQA and Text-Caption<br>
        <font size="2">
            Zhengyuan Yang, Yijuan Lu, <b>Jianfeng Wang</b>, Xi Yin, Dinei Florencio, Lijuan Wang, Cha Zhang, Lei Zhang, Jiebo Luo
            <br>
            12/2020 <a href="https://arxiv.org/pdf/2012.04638.pdf">arxiv-pdf</a>
        </font>
    </p> </li>

    <li> <p>
        MiniVLM: A Smaller and Faster Vision-Language Model<br>
        <font size="2">
            <b>Jianfeng Wang</b>, Xiaowei Hu, Pengchuan Zhang, Xiujun Li,
            Lijuan Wang, Lei Zhang, Jianfeng Gao, Zicheng Liu
            <br>
            12/2020 <a href="https://arxiv.org/pdf/2012.06946.pdf">arxiv-pdf</a>
        </font>
    </p> </li>

    <li> <p>
        Boosting Weakly Supervised Object Detection with Progressive Knowledge Transfer<br>
        <font size="2">
            Yuanyi Zhong, <b>Jianfeng Wang</b>, Jian Peng, Lei Zhang
            <br>
            7/2020 <a href="https://arxiv.org/pdf/2007.07986.pdf">arxiv-pdf</a>
        </font>
    </p> </li>

    <li> <p>
        Hashing-based Non-Maximum Suppression for Crowded Object Detection<br>
        <font size="2">
            <b>Jianfeng Wang</b>, Xi Yin, Lijuan Wang, Lei Zhang
            <br>
            5/2020 <a href="https://arxiv.org/pdf/2005.11426.pdf">arxiv-pdf</a>
        </font>
    </p> </li>

    <li> <p>
        Anchor Box Optimization for Object Detection<br>
        <font size="2">
            Yuanyi Zhong, <b>Jianfeng Wang</b>, Jian Peng, Lei Zhang
            <br>
            1/2020 <a href="https://arxiv.org/pdf/1812.00469.pdf">arxiv-pdf</a>
        </font>
    </p> </li>

</ul>


